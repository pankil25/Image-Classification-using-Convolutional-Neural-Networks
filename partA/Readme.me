# Part A: CNN Architecture from Scratch

- Usage:

  - Pass the path of train dataset folder in **Question 2 "arguments"** method and in **Question 4 "arguments_2"** method :
    
  - Pass the path of test dataset folder in Question 4 "arguments_2" method :
    

The architecture can be customized by adjusting parameters by applying these parameters in sweep such as:

  - Number of Filters: 32, 64, 128
  - Activation Function: ReLU, GELU, SiLU, Mish
  - Filter Organization: Same, Double, Halve
  - Batch Normalization: Yes, No
  - Dropout Value: 0.2, 0.3
  - Learning Rate: 0.001, 0.0001
  - Number of Epochs: 5, 10
  - Number of Neurons in Dense Layer: 128, 256, 512, 1024
  - Batch Size: 32, 64
  - Data Augmentation: Yes, No




- Note:

  - Run Each cell Sequencially Top to Bottom for avoiding errors.
  
  - Each notebook provides detailed instructions and code comments to guide customization and execution.
    
  - It is recommended to have a GPU-enabled environment for faster training.
    
  - Ensure that the dataset folders are correctly structured and contain the necessary images for training and testing.
    
