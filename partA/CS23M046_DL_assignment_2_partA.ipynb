{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7998295,"sourceType":"datasetVersion","datasetId":4709619}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ****Question-1****","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CNN(nn.Module):\n    def __init__(self, input_shape, num_classes, num_filters, filter_size, activation_conv, activation_dense, num_neurons_dense):\n        super(CNN, self).__init__()\n        self.conv_layers = self._create_conv_layers(input_shape[0], num_filters, filter_size, activation_conv)\n        self.fc_layers = nn.Sequential(\n            nn.Linear(256 * 7 * 7, num_neurons_dense),\n            activation_dense,\n            nn.Linear(num_neurons_dense, num_classes)\n        )\n\n    def _create_conv_layers(self, input_channels, num_filters, filter_size, activation_conv):\n        layers = []\n        in_channels = input_channels\n        for _ in range(5):  # Reduced to 5 convolutional layers\n            layers += [\n                nn.Conv2d(in_channels, num_filters, filter_size, padding=1),\n                activation_conv,\n                nn.MaxPool2d(kernel_size=2, stride=2)\n            ]\n            in_channels = num_filters\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc_layers(x)\n        return x\n\n# Example parameters\ninput_shape = (3, 224, 224)  # Example shape compatible with iNaturalist dataset\nnum_classes = 10  # Number of classes in iNaturalist dataset\nnum_filters = 32  # Number of filters in convolutional layers\nfilter_size = 3  # Size of filters\n\n# Define activation functions for convolutional and dense layers\nactivation_conv = nn.ReLU(inplace=True)  # Activation function for convolutional layers\nactivation_dense = nn.ReLU(inplace=True)  # Activation function for dense layer\n\nnum_neurons_dense = 1024  # Number of neurons in dense layer\n\n# Create the model\nmodel = CNN(input_shape, num_classes, num_filters, filter_size, activation_conv, activation_dense, num_neurons_dense)\n\n# Display model summary\nprint(model)\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-03T19:55:15.453250Z","iopub.execute_input":"2024-04-03T19:55:15.453887Z","iopub.status.idle":"2024-04-03T19:55:20.358321Z","shell.execute_reply.started":"2024-04-03T19:55:15.453808Z","shell.execute_reply":"2024-04-03T19:55:20.357021Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"CNN(\n  (conv_layers): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (10): ReLU(inplace=True)\n    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc_layers): Sequential(\n    (0): Linear(in_features=12544, out_features=1024, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Linear(in_features=1024, out_features=10, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Question-2**","metadata":{}},{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import ConcatDataset\nimport torch.nn.functional as F\nfrom PIL import Image\nimport os\nimport random\nfrom collections import defaultdict  # Import defaultdict\nimport numpy as np\nfrom torch.utils.data import random_split\nfrom torch.utils.data import Subset\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:56:33.849453Z","iopub.execute_input":"2024-04-03T19:56:33.849997Z","iopub.status.idle":"2024-04-03T19:56:33.859396Z","shell.execute_reply.started":"2024-04-03T19:56:33.849958Z","shell.execute_reply":"2024-04-03T19:56:33.857883Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\n# Define CNN architecture\nclass CNN(nn.Module):\n    def __init__(self, input_channels, num_classes,num_filters,filter_organization,filter_size,activation,batch_normalization,dropout_value,num_nuerons):\n        super(CNN, self).__init__()\n\n        self.conv_layers = nn.ModuleList()  # ModuleList to store the convolutional layers\n\n        # Define the convolutional layers dynamically using a loop\n        padding=1\n        \n        in_channels = input_channels\n        \n        out_size = 224\n        for i in range(5):\n            self.conv_layers.append(nn.Conv2d(in_channels, num_filters, kernel_size=filter_size, padding=padding))\n            if batch_normalization:\n                self.conv_layers.append(nn.BatchNorm2d(num_filters))\n            if activation == 'relu':\n                self.conv_layers.append(nn.ReLU())  # Add ReLU activation\n            elif activation == 'gelu':\n                self.conv_layers.append(nn.GELU())  # Add GELU activation\n            elif activation == 'silu':\n                self.conv_layers.append(nn.SiLU())  # Add SiLU activation\n            elif activation == 'mish':\n                self.conv_layers.append(Mish())  # Add Mish activation\n            self.conv_layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n            \n            if(dropout_value > 0):\n                self.conv_layers.append(nn.Dropout(dropout_value))\n                \n            \n            in_channels = num_filters\n            \n            \n            pool_kernel_size=2\n            pool_stride=2\n            \n            # Update num_filters based on filter_organization\n            if filter_organization == 'double':\n                num_filters = int(num_filters * 2)\n            elif filter_organization == 'halve':\n                num_filters = int(num_filters / 2)\n            \n            \n                    \n            # Update out_size based on pooling parameters\n            out_size = ((out_size + 2 * padding - pool_kernel_size) // pool_stride )+ 1\n                \n                \n        \n                \n        \n        \n\n        self.fc1 = nn.Linear(in_channels * (out_size-1) * (out_size-1), num_nuerons)\n        self.fc2 = nn.Linear(num_nuerons, num_classes)\n\n    def forward(self, x):\n        for layer in self.conv_layers:\n            x = layer(x)\n\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # Exclude batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n    \n    \nclass Mish(nn.Module):\n    def forward(self, x):\n        return x * torch.tanh(F.softplus(x))\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T20:45:48.174581Z","iopub.execute_input":"2024-04-03T20:45:48.175126Z","iopub.status.idle":"2024-04-03T20:45:48.195153Z","shell.execute_reply.started":"2024-04-03T20:45:48.175090Z","shell.execute_reply":"2024-04-03T20:45:48.194232Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def data_loader(train_data_folder,data_augmentation):\n    \n    \n    without_augmentation_transform =  transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n    # Load the original training dataset\n    train_dataset = datasets.ImageFolder(root=train_data_folder, transform=without_augmentation_transform)\n\n    # Shuffle the dataset\n    indices = list(range(len(train_dataset)))\n    np.random.shuffle(indices)\n    \n    # Calculate the size of the validation set (20% of the training data)\n    val_size = int(0.2 * len(train_dataset))\n    \n    # Calculate the number of samples per class for validation\n    num_classes = len(train_dataset.classes)\n    val_size_per_class = val_size // num_classes\n    \n    # Initialize lists to store indices for training and validation\n    train_indices = []\n    val_indices = []\n    \n    # Iterate through each class to select validation samples\n    for class_idx in range(num_classes):\n        class_indices = [i for i in indices if train_dataset.targets[i] == class_idx]\n        val_indices.extend(class_indices[:val_size_per_class])\n        train_indices.extend(class_indices[val_size_per_class:])\n    \n\n\n    if data_augmentation:\n\n        # Define data augmentation transforms for training data\n        train_transform = transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.Resize((224, 224)),\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n        \n        # Create PyTorch data loaders for the initial dataset\n        train_loader = DataLoader(Subset(train_dataset, train_indices), batch_size=64, shuffle=True)\n        val_loader = DataLoader(Subset(train_dataset, val_indices), batch_size=64, shuffle=True)\n        \n        \n        transformed_dataset = datasets.ImageFolder(root=train_data_folder, transform=train_transform)\n        transformed_loader = DataLoader(Subset(transformed_dataset, train_indices), batch_size=64, shuffle=True)\n        \n\n\n\n\n  \n        \n\n\n        # Concatenate transformed datasets\n        combined_train_dataset = ConcatDataset([train_loader.dataset,transformed_loader.dataset ])  # You can repeat train_dataset_transformed multiple times as needed\n        \n        # Define data loaders for combined datasets\n        train_loader = DataLoader(dataset=combined_train_dataset, batch_size=64, shuffle=True)\n    \n\n    else:\n        # Create PyTorch data loaders for the initial dataset\n        train_loader = DataLoader(Subset(train_dataset, train_indices), batch_size=64, shuffle=True)\n        val_loader = DataLoader(Subset(train_dataset, val_indices), batch_size=64, shuffle=True)\n\n\n    \n    return train_loader , val_loader","metadata":{"execution":{"iopub.status.busy":"2024-04-03T20:30:16.409788Z","iopub.execute_input":"2024-04-03T20:30:16.410325Z","iopub.status.idle":"2024-04-03T20:30:16.427966Z","shell.execute_reply.started":"2024-04-03T20:30:16.410289Z","shell.execute_reply":"2024-04-03T20:30:16.426621Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_folder='/kaggle/input/inaturalist/inaturalist_12K/train'\ndata_augmentation=True\ntrain_loader , val_loader=data_loader(train_data_folder,data_augmentation)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T20:08:54.438517Z","iopub.execute_input":"2024-04-03T20:08:54.438943Z","iopub.status.idle":"2024-04-03T20:08:56.343514Z","shell.execute_reply.started":"2024-04-03T20:08:54.438913Z","shell.execute_reply":"2024-04-03T20:08:56.342283Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print(len(train_loader))\nprint(len(val_loader))\nprint(len(p))\nprint(len(q))\nprint(len(r))\nprint(len(s))\nprint(len(t))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T20:03:53.198854Z","iopub.execute_input":"2024-04-03T20:03:53.200145Z","iopub.status.idle":"2024-04-03T20:03:53.207759Z","shell.execute_reply.started":"2024-04-03T20:03:53.200103Z","shell.execute_reply":"2024-04-03T20:03:53.206298Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"251\n32\n9999\n16018\n8009\n1990\n9999\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Define training function\ndef train(model, train_loader, optimizer, criterion, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    train_loss = running_loss / len(train_loader)\n    train_accuracy = correct / total\n    return train_loss, train_accuracy\n\n# Define testing function\ndef validate(model, val_loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    val_loss = running_loss / len(val_loader)\n    val_accuracy = correct / total\n    return val_loss, val_accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T20:09:04.080927Z","iopub.execute_input":"2024-04-03T20:09:04.081413Z","iopub.status.idle":"2024-04-03T20:09:04.095085Z","shell.execute_reply.started":"2024-04-03T20:09:04.081377Z","shell.execute_reply":"2024-04-03T20:09:04.093818Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_data_folder='/kaggle/input/inaturalist/inaturalist_12K/train'\n\ntrain_dataset = datasets.ImageFolder(root=train_data_folder)\n\ntrain_loader , val_loader=data_loader(train_data_folder,data_augmentation)\n\n# Model parameters\ninput_channels = 3\nnum_classes = len(train_dataset.classes)\nnum_filters = 32\n\n# Choose activation function for convolutional layers\nactivation = 'mish'  # You can choose from 'ReLU', 'GELU', 'SiLU', 'Mish'\n\nfilter_organization='double' \n\n\nfilter_size=3\nbatch_normalization=True\ndropout_value=0.3\nnum_nuerons=128\ndata_augmentation=True\n\n\n# Create model instance\nmodel = CNN(input_channels, num_classes, num_filters,filter_organization,filter_size,activation,batch_normalization,dropout_value,num_nuerons).to(device)\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n\n\n# Training loop\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, device)\n    val_loss, val_accuracy = validate(model, val_loader , criterion, device)\n    print(f\"Epoch {epoch+1}/{num_epochs},\\n Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f},\\n Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:54:54.662196Z","iopub.execute_input":"2024-04-03T21:54:54.663763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T21:54:46.596208Z","iopub.execute_input":"2024-04-03T21:54:46.597227Z","iopub.status.idle":"2024-04-03T21:54:46.603305Z","shell.execute_reply.started":"2024-04-03T21:54:46.597173Z","shell.execute_reply":"2024-04-03T21:54:46.602126Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"0.22261306532663316\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Question 4","metadata":{}},{"cell_type":"code","source":"# Define testing function\ndef test(model, test_loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    test_loss = running_loss / len(test_loader)\n    test_accuracy = correct / total\n    return test_loss, test_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:55:34.834060Z","iopub.status.idle":"2024-04-03T19:55:34.834567Z","shell.execute_reply.started":"2024-04-03T19:55:34.834347Z","shell.execute_reply":"2024-04-03T19:55:34.834368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"without_augmentation_transform =  transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\ntest_data_folder='/kaggle/input/inaturalist/inaturalist_12K/val'\n\ntest_dataset = datasets.ImageFolder(root=test_data_folder,transform=without_augmentation_transform)\ntrain_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n\ninput_channels=3\nnum_classes=10\nnum_filters=32\nfilter_organization='double'\nfilter_size=3\nactivation='relu'\nbatch_normalization=True\ndropout_value=0.3\nnum_nuerons=128\n\n# Create model instance\nbest_model = CNN(input_channels, num_classes, num_filters,filter_organization,filter_size,activation,batch_normalization,dropout_value,num_nuerons).to(device)\n\n\ntest_loss, test_accuracy =test(best_model, test_loader, criterion, device)\n\nprint(f'Test Loss :{test_loss}')\nprint(f'Test Accuracy :{test_accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:55:34.836359Z","iopub.status.idle":"2024-04-03T19:55:34.836803Z","shell.execute_reply.started":"2024-04-03T19:55:34.836597Z","shell.execute_reply":"2024-04-03T19:55:34.836616Z"},"trusted":true},"execution_count":null,"outputs":[]}]}