{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7998295,"sourceType":"datasetVersion","datasetId":4709619}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ****Question-1****","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CNN(nn.Module):\n    def __init__(self, input_shape, num_classes, num_filters, filter_size, activation_conv, activation_dense, num_neurons_dense):\n        super(CNN, self).__init__()\n        self.conv_layers = self._create_conv_layers(input_shape[0], num_filters, filter_size, activation_conv)\n        self.fc_layers = nn.Sequential(\n            nn.Linear(256 * 7 * 7, num_neurons_dense),\n            activation_dense,\n            nn.Linear(num_neurons_dense, num_classes)\n        )\n\n    def _create_conv_layers(self, input_channels, num_filters, filter_size, activation_conv):\n        layers = []\n        in_channels = input_channels\n        for _ in range(5):  # Reduced to 5 convolutional layers\n            layers += [\n                nn.Conv2d(in_channels, num_filters, filter_size, padding=1),\n                activation_conv,\n                nn.MaxPool2d(kernel_size=2, stride=2)\n            ]\n            in_channels = num_filters\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc_layers(x)\n        return x\n\n# Example parameters\ninput_shape = (3, 224, 224)  # Example shape compatible with iNaturalist dataset\nnum_classes = 10  # Number of classes in iNaturalist dataset\nnum_filters = 32  # Number of filters in convolutional layers\nfilter_size = 3  # Size of filters\n\n# Define activation functions for convolutional and dense layers\nactivation_conv = nn.ReLU(inplace=True)  # Activation function for convolutional layers\nactivation_dense = nn.ReLU(inplace=True)  # Activation function for dense layer\n\nnum_neurons_dense = 1024  # Number of neurons in dense layer\n\n# Create the model\nmodel = CNN(input_shape, num_classes, num_filters, filter_size, activation_conv, activation_dense, num_neurons_dense)\n\n# Display model summary\nprint(model)\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-05T14:43:11.787823Z","iopub.execute_input":"2024-04-05T14:43:11.788324Z","iopub.status.idle":"2024-04-05T14:43:16.414375Z","shell.execute_reply.started":"2024-04-05T14:43:11.788288Z","shell.execute_reply":"2024-04-05T14:43:16.413256Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"CNN(\n  (conv_layers): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (10): ReLU(inplace=True)\n    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc_layers): Sequential(\n    (0): Linear(in_features=12544, out_features=1024, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Linear(in_features=1024, out_features=10, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Question-2**","metadata":{}},{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import ConcatDataset\nimport torch.nn.functional as F\nfrom PIL import Image\nimport os\nimport random\nfrom collections import defaultdict  # Import defaultdict\nimport numpy as np\nfrom torch.utils.data import random_split\nfrom torch.utils.data import Subset\nimport matplotlib.pyplot as plt\nimport wandb\nfrom tqdm import tqdm\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:43:16.416203Z","iopub.execute_input":"2024-04-05T14:43:16.416600Z","iopub.status.idle":"2024-04-05T14:43:20.929619Z","shell.execute_reply.started":"2024-04-05T14:43:16.416571Z","shell.execute_reply":"2024-04-05T14:43:20.928547Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n# Define CNN architecture\nclass CNN(nn.Module):\n    def __init__(self, input_channels, num_classes,num_filters,filter_organization,filter_size,activation,batch_normalization,dropout_value,num_nuerons):\n        super(CNN, self).__init__()\n\n        self.conv_layers = nn.ModuleList()  # ModuleList to store the convolutional layers\n\n        # Define the convolutional layers dynamically using a loop\n        padding=1\n        \n        in_channels = input_channels\n        \n        out_size = 224\n        for i in range(5):\n            self.conv_layers.append(nn.Conv2d(in_channels, num_filters, kernel_size=filter_size, padding=padding))\n            if batch_normalization:\n                self.conv_layers.append(nn.BatchNorm2d(num_filters))\n            if activation == 'relu':\n                self.conv_layers.append(nn.ReLU())  # Add ReLU activation\n            elif activation == 'gelu':\n                self.conv_layers.append(nn.GELU())  # Add GELU activation\n            elif activation == 'silu':\n                self.conv_layers.append(nn.SiLU())  # Add SiLU activation\n            elif activation == 'mish':\n                self.conv_layers.append(Mish())  # Add Mish activation\n            self.conv_layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n            \n            if(dropout_value > 0):\n                self.conv_layers.append(nn.Dropout(dropout_value))\n                \n            \n            in_channels = num_filters\n            \n            \n            pool_kernel_size=2\n            pool_stride=2\n            \n            # Update num_filters based on filter_organization\n            if filter_organization == 'double':\n                num_filters = int(num_filters * 2)\n            elif filter_organization == 'halve':\n                num_filters = int(num_filters / 2)\n            elif filter_organization == 'same':\n                num_filters=num_filters\n            \n            \n                    \n            # Update out_size based on pooling parameters\n            out_size = ((out_size + 2 * padding - pool_kernel_size) // pool_stride )+ 1\n                \n                \n        \n                \n        \n        \n\n        self.fc1 = nn.Linear(in_channels * (out_size-1) * (out_size-1), num_nuerons)\n        self.fc2 = nn.Linear(num_nuerons, num_classes)\n\n    def forward(self, x):\n        for layer in self.conv_layers:\n            x = layer(x)\n\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # Exclude batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n    \n    \nclass Mish(nn.Module):\n    def forward(self, x):\n        return x * torch.tanh(F.softplus(x))\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:43:20.931133Z","iopub.execute_input":"2024-04-05T14:43:20.931444Z","iopub.status.idle":"2024-04-05T14:43:20.947691Z","shell.execute_reply.started":"2024-04-05T14:43:20.931419Z","shell.execute_reply":"2024-04-05T14:43:20.946608Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def data_loader(train_data_folder,batch_size,data_augmentation):\n    \n    \n    without_augmentation_transform =  transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n    # Load the original training dataset\n    train_dataset = datasets.ImageFolder(root=train_data_folder, transform=without_augmentation_transform)\n\n    # Shuffle the dataset\n    indices = list(range(len(train_dataset)))\n    np.random.shuffle(indices)\n    \n    # Calculate the size of the validation set (20% of the training data)\n    val_size = int(0.2 * len(train_dataset))\n    \n    # Calculate the number of samples per class for validation\n    num_classes = len(train_dataset.classes)\n    val_size_per_class = val_size // num_classes\n    \n    # Initialize lists to store indices for training and validation\n    train_indices = []\n    val_indices = []\n    \n    # Iterate through each class to select validation samples\n    for class_idx in range(num_classes):\n        class_indices = [i for i in indices if train_dataset.targets[i] == class_idx]\n        val_indices.extend(class_indices[:val_size_per_class])\n        train_indices.extend(class_indices[val_size_per_class:])\n    \n\n\n    if data_augmentation:\n\n        # Define data augmentation transforms for training data\n        train_transform = transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.Resize((224, 224)),\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n        \n        # Create PyTorch data loaders for the initial dataset\n        train_loader = DataLoader(Subset(train_dataset, train_indices), batch_size=batch_size, shuffle=True)\n        val_loader = DataLoader(Subset(train_dataset, val_indices), batch_size=batch_size, shuffle=True)\n        \n        \n        transformed_dataset = datasets.ImageFolder(root=train_data_folder, transform=train_transform)\n        transformed_loader = DataLoader(Subset(transformed_dataset, train_indices), batch_size=batch_size, shuffle=True)\n        \n\n\n\n\n  \n        \n\n\n        # Concatenate transformed datasets\n        combined_train_dataset = ConcatDataset([train_loader.dataset,transformed_loader.dataset ])  # You can repeat train_dataset_transformed multiple times as needed\n        \n        # Define data loaders for combined datasets\n        train_loader = DataLoader(dataset=combined_train_dataset, batch_size=batch_size, shuffle=True)\n    \n\n    else:\n        # Create PyTorch data loaders for the initial dataset\n        train_loader = DataLoader(Subset(train_dataset, train_indices), batch_size=batch_size, shuffle=True)\n        val_loader = DataLoader(Subset(train_dataset, val_indices), batch_size=batch_size, shuffle=True)\n\n\n    \n    return train_loader , val_loader","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:43:20.950946Z","iopub.execute_input":"2024-04-05T14:43:20.951540Z","iopub.status.idle":"2024-04-05T14:43:20.969874Z","shell.execute_reply.started":"2024-04-05T14:43:20.951501Z","shell.execute_reply":"2024-04-05T14:43:20.968791Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n# Define training function\ndef train(model, train_loader, optimizer, criterion, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    train_loss = running_loss / len(train_loader)\n    train_accuracy = correct / total\n    return train_loss, train_accuracy\n\n# Define testing function\ndef validate(model, val_loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    val_loss = running_loss / len(val_loader)\n    val_accuracy = correct / total\n    return val_loss, val_accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:43:20.971025Z","iopub.execute_input":"2024-04-05T14:43:20.971312Z","iopub.status.idle":"2024-04-05T14:43:20.984653Z","shell.execute_reply.started":"2024-04-05T14:43:20.971288Z","shell.execute_reply":"2024-04-05T14:43:20.983767Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# def arguments(num_filters,batch_size,activation,filter_organization,batch_normalization,data_augmentation,dropout_value,num_nuerons,lr,num_epochs):\n    \n\n\n#     # Set random seed\n#     torch.manual_seed(42)\n    \n    \n#     # Set device\n#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n#     train_data_folder='/kaggle/input/inaturalist/inaturalist_12K/train'\n\n#     train_dataset = datasets.ImageFolder(root=train_data_folder)\n    \n\n\n    \n\n#     # Model parameters\n#     input_channels = 3\n#     num_classes = len(train_dataset.classes)\n\n\n\n\n\n\n\n#     filter_size=3\n    \n#     if(batch_normalization == \"Yes\"):\n#         batch_normalization_val=True\n#     elif(batch_normalization == \"No\"):\n#         batch_normalization_val=False\n        \n    \n    \n    \n    \n#     if(data_augmentation == \"Yes\"):\n#         data_augmentation_val=True\n#     elif(data_augmentation == \"No\"):\n#         data_augmentation_val=False\n    \n#     train_loader , val_loader=data_loader(train_data_folder,batch_size,data_augmentation_val)\n\n#     # Create model instance\n#     model = CNN(input_channels, num_classes, num_filters,filter_organization,filter_size,activation,batch_normalization_val,dropout_value,num_nuerons).to(device)\n\n#     # Loss function and optimizer\n#     criterion = nn.CrossEntropyLoss()\n#     optimizer = optim.Adam(model.parameters(), lr)\n\n\n\n#     # Training loop\n  \n#     for epoch in range(num_epochs):\n#         epoch_progress = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n#         train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, device)\n#         val_loss, val_accuracy = validate(model, val_loader , criterion, device)\n        \n#         # Log to Weights & Biases\n#         wandb.log({\n#             \"Epoch\": epoch + 1,\n#             \"Train_Accuracy\": train_accuracy,\n#             \"Train_Loss\": train_loss,\n#             \"Val_Accuracy\": val_accuracy,\n#             \"Val_Loss\": val_loss\n#         })\n#         print(f\"Epoch {epoch+1}/{num_epochs},\\n Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f},\\n Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:43:20.986264Z","iopub.execute_input":"2024-04-05T14:43:20.986929Z","iopub.status.idle":"2024-04-05T14:43:21.000046Z","shell.execute_reply.started":"2024-04-05T14:43:20.986893Z","shell.execute_reply":"2024-04-05T14:43:20.999201Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# wandb.login()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:43:21.001359Z","iopub.execute_input":"2024-04-05T14:43:21.001804Z","iopub.status.idle":"2024-04-05T14:43:21.014082Z","shell.execute_reply.started":"2024-04-05T14:43:21.001771Z","shell.execute_reply":"2024-04-05T14:43:21.013173Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# # sweep_config = {\n# #     'method': 'bayes',\n# #     'metric': {'goal': 'maximize', 'name': 'Val_Accuracy'},\n# #     'parameters': {\n# #         'num_filters': {'values': [32, 64, 128]},\n# #         'activation': {'values': ['relu', 'gelu', 'silu', 'mish']},\n# #         'filter_organization': {'values': ['same', 'double', 'halve']},\n# #         'batch_normalization': {'values': ['Yes', 'No']},\n# #         'dropout_value': {'values': [0.2, 0.3]},\n# #         'learning_rate': {'values': [0.001, 0.0001]},\n# #         'num_epochs': {'values': [5,10]},\n# #         'dense_neurons': {'values': [128, 256, 512, 1024]},\n# #         'batch_size': {'values': [32, 64]},\n# #         'data_augmentation': {'values': ['Yes', 'No']}\n# #     }\n# # }\n\n# sweep_config = {\n#     'method': 'random',\n#     'metric': {'goal': 'maximize', 'name': 'Val_Accuracy'},\n#     'parameters': {\n#         'num_filters': {'values': [32,64,128]},\n#         'activation': {'values': ['relu', 'gelu', 'silu', 'mish']},\n#         'filter_organization': {'values': ['same', 'double', 'halve']},\n#         'batch_normalization': {'values': ['Yes', 'No']},\n#         'dropout_value': {'values': [0.2,0.3]},\n#         'learning_rate': {'values': [0.001,0.0001]},\n#         'num_epochs': {'values': [5]},\n#         'dense_neurons': {'values': [128, 256,512]},\n#         'batch_size': {'values': [32,64]},\n#         'data_augmentation': {'values': ['Yes', 'No']}\n#     }\n# }\n\n\n\n\n\n\n# # Create sweep\n# sweep_id = wandb.sweep(sweep=sweep_config, project=\"DL_Assignment_2_CS23M046\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:43:21.015206Z","iopub.execute_input":"2024-04-05T14:43:21.015894Z","iopub.status.idle":"2024-04-05T14:43:21.024811Z","shell.execute_reply.started":"2024-04-05T14:43:21.015867Z","shell.execute_reply":"2024-04-05T14:43:21.024011Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# def main():\n    \n#     # Initialize wandb\n#     with wandb.init() as run:\n\n#         config = wandb.config\n        \n#         run_name=\"activation_\"+str(config.activation)+\"_num_filters_\"+str(config.num_filters)+\"_dense_\"+str(config.dense_neurons)+\"_lr_\"+str(config.learning_rate)\n#         wandb.run.name=run_name\n        \n#         arguments(config.num_filters,config.batch_size,config.activation,config.filter_organization,config.batch_normalization,config.data_augmentation,config.dropout_value,config.dense_neurons,config.learning_rate,config.num_epochs)\n\n\n\n\n\n\n# # Run sweep\n# wandb.agent(sweep_id, function=main, count=15)\n\n# wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:43:21.025933Z","iopub.execute_input":"2024-04-05T14:43:21.026174Z","iopub.status.idle":"2024-04-05T14:43:21.038352Z","shell.execute_reply.started":"2024-04-05T14:43:21.026153Z","shell.execute_reply":"2024-04-05T14:43:21.037549Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Question 4","metadata":{}},{"cell_type":"code","source":"# Define testing function\ndef test(model, test_loader, optimizer, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    test_loss = running_loss / len(test_loader)\n    test_accuracy = correct / total\n    return test_loss, test_accuracy\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:43:21.041003Z","iopub.execute_input":"2024-04-05T14:43:21.041291Z","iopub.status.idle":"2024-04-05T14:43:21.052605Z","shell.execute_reply.started":"2024-04-05T14:43:21.041267Z","shell.execute_reply":"2024-04-05T14:43:21.051671Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Function to get predictions from the model\ndef get_predictions(model, test_loader):\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for inputs, _ in test_loader:\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            predictions.extend(predicted.cpu().numpy())\n    return predictions\n\n# Function to display images in a grid\ndef show_images_grid(best_model,test_loader,num_class,rows, cols):\n    fig, axes = plt.subplots(rows, cols, figsize=(15, 15))\n    # Get predictions\n    predictions = get_predictions(best_model, test_loader)\n    i=0\n    temp_index=0\n    visited=set()\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        for image, label, pred in zip(images, labels, predictions[i]):\n            ci=label.item()\n            if ci not in visited and len(visited) < 10:\n                visited.add(label.item())\n                image = image.cpu()  # Move image to CPU\n                axes[temp_index, 0].text(0.5, 0.5, f\"Actual label: {ci}\", ha='center')\n                axes[temp_index, 0].axis('off')\n                axes[temp_index, 1].imshow(image.permute(1, 2, 0).numpy())\n                axes[temp_index, 1].axis('off')\n                axes[temp_index, 2].text(0.5, 0.5, f\"Predicted label: {predictions[i].item()}\", ha='center')\n                axes[temp_index, 2].axis('off')\n                temp_index=temp_index +1\n            \n        i=i+1\n        \n        if(len(visited)>=10):\n            break\n        \n    plt.tight_layout()\n#     image = wandb.Image(plt)\n#     wandb.log({\"Sample Predictions for Test Data\": image})\n    plt.show()\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:43:21.054404Z","iopub.execute_input":"2024-04-05T14:43:21.054756Z","iopub.status.idle":"2024-04-05T14:43:21.067396Z","shell.execute_reply.started":"2024-04-05T14:43:21.054703Z","shell.execute_reply":"2024-04-05T14:43:21.066461Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set random seed\ntorch.manual_seed(42)\n\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nwithout_augmentation_transform =  transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_data_folder='/kaggle/input/inaturalist/inaturalist_12K/train'\n\ntrain_dataset = datasets.ImageFolder(root=train_data_folder)\n\n\n\ninput_channels=3\nnum_classes=10\nnum_filters=128\nfilter_organization='double'\nfilter_size=3\nactivation='mish'\nbatch_normalization=True\ndropout_value=0.3\nnum_nuerons=1024\ndata_augmentation_val =True\nnum_epochs=10\nbatch_size=32\nlr = 0.0001\n\ntrain_loader , _ =data_loader(train_data_folder,batch_size,data_augmentation_val)\n\n\ntest_data_folder='/kaggle/input/inaturalist/inaturalist_12K/val'\n\ntest_dataset = datasets.ImageFolder(root=test_data_folder,transform=without_augmentation_transform)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n\n# Create model instance\nbest_model = CNN(input_channels, num_classes, num_filters,filter_organization,filter_size,activation,batch_normalization,dropout_value,num_nuerons).to(device)\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(best_model.parameters(), lr)\n\nfor epoch in range(num_epochs):\n    epoch_progress = tqdm(test_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n    train_loss, train_accuracy = train(best_model, train_loader, optimizer, criterion, device)\n    test_loss, test_accuracy =test(best_model, test_loader, optimizer, criterion, device)\n\n    print(f'Test Loss :{test_loss}')\n    print(f'Test Accuracy :{test_accuracy}')\n\n\n\nrow=10\ncol=3\n# Display images along with their predicted labels\n#show_images_grid(best_model,test_loader,num_classes,row,col)  # Adjust rows and columns as needed\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:43:36.533749Z","iopub.execute_input":"2024-04-05T14:43:36.534782Z","iopub.status.idle":"2024-04-05T16:17:48.702132Z","shell.execute_reply.started":"2024-04-05T14:43:36.534719Z","shell.execute_reply":"2024-04-05T16:17:48.701146Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Epoch 1/10:   0%|          | 0/63 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Test Loss :2.039083590583196\nTest Accuracy :0.277\n","output_type":"stream"},{"name":"stderr","text":"\n                                                  \u001b[A\r","output_type":"stream"},{"name":"stdout","text":"Test Loss :1.9483964045842488\nTest Accuracy :0.316\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10:   0%|          | 0/63 [00:00<?, ?it/s]\n                                                  \u001b[A","output_type":"stream"},{"name":"stdout","text":"Test Loss :1.8930447442190987\nTest Accuracy :0.3455\n","output_type":"stream"},{"name":"stderr","text":"\n                                                  \u001b[A\r","output_type":"stream"},{"name":"stdout","text":"Test Loss :1.875595005731734\nTest Accuracy :0.3475\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10:   0%|          | 0/63 [00:00<?, ?it/s]\n                                                  \u001b[A","output_type":"stream"},{"name":"stdout","text":"Test Loss :1.8180853639330183\nTest Accuracy :0.3555\n","output_type":"stream"},{"name":"stderr","text":"\n                                                  \u001b[A\r","output_type":"stream"},{"name":"stdout","text":"Test Loss :1.8808400782327803\nTest Accuracy :0.3505\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10:   0%|          | 0/63 [00:00<?, ?it/s]\n                                                  \u001b[A","output_type":"stream"},{"name":"stdout","text":"Test Loss :1.8708994029060242\nTest Accuracy :0.3735\n","output_type":"stream"},{"name":"stderr","text":"\n                                                  \u001b[A\r","output_type":"stream"},{"name":"stdout","text":"Test Loss :1.7454981766049824\nTest Accuracy :0.4085\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10:   0%|          | 0/63 [00:00<?, ?it/s]\n                                                  \u001b[A","output_type":"stream"},{"name":"stdout","text":"Test Loss :1.8475647540319533\nTest Accuracy :0.383\n","output_type":"stream"},{"name":"stderr","text":"\n                                                  ]\u001b[A\r","output_type":"stream"},{"name":"stdout","text":"Test Loss :1.773476763377114\nTest Accuracy :0.4075\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to display images with labels in a grid\ndef imshow_grid(images, actual_labels, predicted_labels, title):\n    # Create a grid of images\n    grid = torchvision.utils.make_grid(images, nrow=3, padding=10)\n    npimg = grid.numpy()\n    \n    # Display the grid with labels\n    plt.figure(figsize=(15, 15))\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.title(title)\n    plt.axis('off')\n    plt.show()\n    \n    # Print actual and predicted labels\n    for actual, predicted in zip(actual_labels, predicted_labels):\n        print(f\"Actual: {actual}\\tPredicted: {predicted}\")\n\n# Define a function to evaluate the model on the test loader\ndef evaluate_model(model, test_loader, classes):\n    model.eval()\n    class_images = {cls: [] for cls in classes}\n    actual_labels = []\n    predicted_labels = []\n    grid_filled = False\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n\n            for i in range(len(labels)):\n                label = labels[i].item()\n                predicted_label = predicted[i].item()\n\n                class_name = classes[label]\n\n                # Add the image to the list of images for its class\n                class_images[class_name].append(images[i].cpu())\n                actual_labels.append(classes[label])\n                predicted_labels.append(classes[predicted_label])\n\n                # Check if the grid is filled\n                if len(actual_labels) >= 10 * 3:\n                    grid_filled = True\n                    break\n            if grid_filled:\n                break\n\n    # Display 3 images for each class in a grid\n    for class_name, images in class_images.items():\n        if len(images) >= 3:\n            # Select only 3 images per class\n            images_to_show = images[:3]\n            actual_labels_to_show = [class_name] * 3\n            predicted_labels_to_show = [predicted_labels[i] for i in range(len(predicted_labels)) if actual_labels[i] == class_name][:3]\n            imshow_grid(images_to_show, actual_labels_to_show, predicted_labels_to_show, f'Class: {class_name}')\n\n# Assuming you have a PyTorch model and a test loader\n# model = YourModel()\n# test_loader = YourTestLoader()\n# classes = YourClassesList()\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n\n# Evaluate model\nevaluate_model(best_model, test_loader, classes)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{},"execution_count":null,"outputs":[]}]}